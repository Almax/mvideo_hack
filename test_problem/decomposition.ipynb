{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "import pymorphy2\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15587, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('feedback.csv/X_train.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sku', 'categoryLevel1Id', 'categoryLevel2Id', 'brandId', 'property',\n",
       "       'userName', 'reting', 'date', 'comment', 'commentNegative',\n",
       "       'commentPositive'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2698.000000\n",
       "mean        5.777242\n",
       "std         5.986300\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         3.000000\n",
       "75%         8.000000\n",
       "max        25.000000\n",
       "Name: sku, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sku.value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = util.prepare_texts(data.comment, bigrams = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Плита полностью отрабатывает свои деньги.Готовлю много.Пеку.Дешево, но сердито.Столкнулись с гарантийным ремонтом. Ребята быстро отреагировали.Всем советую\n",
      "плита полностью отрабатывать свой деньги.готовить много.пеку.дешево , но сердито.столкнуться с гарантийный ремонт . ребята быстро отреагировали.всем советовать\n",
      "\n",
      "Искали простенькую и недорогую вытяжку для кухни, привлекла эта. Она маленькая и компактная, легко встраивается. Моется тоже легко. для нашей маленькой кухни её вполне хватает. тянет воздух отлично, теперь на кухне не душно во время готовки, не пахнет жареным луком и другими продуктами. Производительность хорошая, при этом вытяжка совсем не шумная. Удобное управление, 3 скорости, можно выбрать любую в зависимости от желаемой мощности. Освещает плиту хорошо.\n",
      "искать простенький и недорогой вытяжка для кухня , привлечь этот . она маленький и компактный , легко встраиваться . мыться тоже легко . для наш маленькая кухня её вполне хватать . тянуть воздух отлично , теперь на кухня не душный в время готовка , не пахнуть жареный лук и другой продукт . производительность хороший , при это вытяжка совсем не шумный . удобный управление , 3 скорость , можно выбрать любой в зависимость от желаемый мощность . освещать плита хорошо .\n",
      "\n",
      "Одни плюсы\n",
      "один плюс\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, t in texts.sample(3).items():\n",
    "    print(data.comment[i])\n",
    "    print(t)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2698,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_by_sku = texts.groupby(data.sku).aggregate(lambda x: ' '.join(x))\n",
    "texts_by_sku.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopWords = stopwords.words('russian')\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_df=0.5, min_df=10,\n",
    "                                stop_words=stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4654\n"
     ]
    }
   ],
   "source": [
    "tf_vectorizer.fit(texts)\n",
    "print(len(tf_vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2698, 4654)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = tf_vectorizer.transform(texts_by_sku)\n",
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation( max_iter=10, n_topics=5,\n",
    "                                    learning_method='online',\n",
    "                                    learning_offset=50.,\n",
    "                                    n_jobs = -1,\n",
    "                                    verbose = 1,\n",
    "                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_words(model, feature_names, n_top_words):\n",
    "    tops = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        tops.append(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    return tops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=40, random_state=1, init = 'nndsvdar',\n",
    "          alpha=.1, l1_ratio=.5, max_iter = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.1, beta=1, eta=0.1, init='nndsvdar', l1_ratio=0.5, max_iter=30,\n",
       "  n_components=40, nls_max_iter=2000, random_state=1, shuffle=False,\n",
       "  solver='cd', sparseness=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf.fit(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['весь советовать отличный ничто пока общий модель супер очень отлично',\n",
       " 'пылесос уборка фильтр мощность пыль контейнер ковёр мыть щётка мешок',\n",
       " 'год работать пользоваться сломаться новый месяц назад отличный нарекание покупать',\n",
       " 'чайник крышка вода дизайн пластик кипятить вод запах это шуметь',\n",
       " 'волос выпрямитель очень выпрямлять нагреваться щипец пользоваться быстро температура локон',\n",
       " 'машинка стирка стирать машина отжим бельё барабан программа режим время',\n",
       " 'телефон камера экран очень кнопка день звук _brackets_positive динамик удобный',\n",
       " 'ноутбук ноут проблема работать это экран игра очень минус диск',\n",
       " 'телевизор картинка изображение тв звук канал качество фильм смотреть usb',\n",
       " 'вода вод это горячий водонагреватель время отключение весь мыть уборка',\n",
       " 'плеер видео звук кнопка наушник экран музыка работать файл часы',\n",
       " 'сок жмых соковыжималка яблоко сухой очень купить выжимать стакан легко',\n",
       " 'работать блок комната кондиционер вентилятор модель внешний режим шум охлаждать',\n",
       " 'утюг гладить пара глажка подошва пользоваться парогенератор вода вещий паровой',\n",
       " 'наушник звук ухо бас хороший провод отличный музыка слушать громкость',\n",
       " 'кофе кофеварка кофемашин машина кофемолка помол очень варить вкусный отличный',\n",
       " 'это который весь ещё самый плюс купить минус думать брать',\n",
       " 'бритва бритьё брить раздражение бриться щетина станок кожа чисто шея',\n",
       " 'игра играть ps3 приставка график консоль просто который сюжет самый',\n",
       " '_period ещё весь _brackets_positive мочь купить большой правда деньга проблема',\n",
       " 'мясорубка мясо крутить фарш нож пользоваться весь очень довольный быстро',\n",
       " 'плита духовка конфорка панель ручка поверхность печь пользоваться решётка время',\n",
       " 'температура вод термопот горячий кнопка быстро время запах режим удобный',\n",
       " 'хлеб получаться тостер печка печь очень рецепт хлебопечка корочка весь',\n",
       " 'хороший нормальный минус покупать деньга плюс брать очень нравиться отлично',\n",
       " 'насадка машинка набор стричь маникюр стрижка пользоваться работать муж весь',\n",
       " '_many_exclamations супер просто отличный советовать довольный весь покупать пожалеть взять',\n",
       " 'фен волос укладка пользоваться воздух щётка насадка очень сушить укладывать',\n",
       " 'увлажнитель влажность комната вода фильтр работать пара воздух большой налёт',\n",
       " 'вытяжка кухня скорость фильтр запах работать стекло подсветка дизайн шуметь',\n",
       " 'купить назад довольный очень день _brackets_positive месяц неделя сразу хотеть',\n",
       " 'щётка зуб насадка чистить зубной который десна весь чистка очень',\n",
       " 'цена качество отличный модель удобный брать свой мощность компактный рекомендовать',\n",
       " 'посуда мыть машина мойка весь машинка пользоваться кастрюля отмывать время',\n",
       " 'весы вес показывать килограмм батарейка весь погрешность день точный месяц',\n",
       " 'очень довольный удобный удобно быстро понравиться советовать покупка рекомендовать легко',\n",
       " 'готовить получаться просто йогурт вкусный пароварка вещь делать приготовление йогуртница',\n",
       " 'эпилятор волосок пользоваться модель насадка нога волос эпиляция кожа бикини',\n",
       " 'блендер миксер чаша пользоваться комбайн большой тесто взбивать делать весь',\n",
       " 'весь айфон аппарат пользоваться работать мочь который iphone большой ещё']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_words(nmf, counts_names, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf_top = get_top_words(nmf, counts_names, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_tran = nmf.transform(tf_vectorizer.transform(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_topics = np.argmax(nmf_tran, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Берите не пожалеете... звук отличный.. плеер супер.. работает сразу с несколькими приложениями, нет тормозов..минусов у него нет\n",
      "10 плеер видео звук\n"
     ]
    }
   ],
   "source": [
    "for i, text in data.comment.sample(1).items():\n",
    "    print(text)\n",
    "    topic = pred_topics[i]\n",
    "    print(topic, nmf_top[topic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_jobs=-1, n_topics=5, perp_tol=0.1, random_state=0,\n",
       "             topic_word_prior=None, total_samples=1000000.0, verbose=1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.fit(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: игра телефон ноутбук весь ноут это экран играть память _period\n",
      "Topic #1: очень год весь вода это купить чайник машинка работать утюг\n",
      "Topic #2: пылесос очень волос насадка фильтр год пользоваться это мощность щётка\n",
      "Topic #3: очень весь это пользоваться купить год довольный просто плита _many_exclamations\n",
      "Topic #4: весь очень это хороший купить _period качество работать отличный звук\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_words(lda, counts_names, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import timeit\n",
    "import datetime\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nile.api.v1 import clusters\n",
    "from nile.api.v1 import aggregators as na\n",
    "from qb2.api.v1 import filters as qf\n",
    "from nile.api.v1 import filters as nf\n",
    "from nile.api.v1 import extractors as ne\n",
    "import ast\n",
    "from collections import defaultdict\n",
    "from keras.preprocessing import sequence\n",
    "import time\n",
    "from gensim.models import word2vec\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "import matplotlib\n",
    "import pickle\n",
    "import gc\n",
    "from keras.models import load_model\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from string import punctuation\n",
    "from __future__ import print_function\n",
    "from time import time\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer,HashingVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from tqdm import tqdm\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LDA models with tf features, n_samples=2000 and n_features=20000...\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "\n",
    "for n_topics in [100]:\n",
    "    lda = LatentDirichletAllocation( max_iter=40,n_topics=n_topics,\n",
    "                                    learning_method=None,\n",
    "                                    learning_offset=50.,\n",
    "                                    random_state=0)#,n_jobs = 16)\n",
    "    tf = tf_vectorizer.fit_transform(res_2)\n",
    "    t0 = time()\n",
    "    lda.fit(tf)\n",
    "    print(\"done in %0.3fs.\" % (time() - t0))\n",
    "    print(\"\\nTopics in LDA model:\")\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "    print_top_words(lda, tf_feature_names, n_top_words)\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    print('-------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
